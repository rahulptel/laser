# Prediction task
# classification or regression
pred_task: classification
device: cpu
threshold: 0.5
round_upto: 1

prob:
  name: knapsack
  num_objs: 7
  num_vars: 40
  size: ${prob.num_objs}_${prob.num_vars}
  order: MinWt
  layer_norm_const: 100
  state_norm_const: 1000

train:
  epochs: 1
  from_pid: 0
  to_pid: 5
  inst_per_step: 100
  neg_pos_ratio: 1
  min_samples: 0
  batch_size: 512
  shuffle: true
  verbose: false
  log_dir: train_log
  flag_layer_penalty: true
  # layer in [0, 1], 0 for root and 1 for terminal
  # const:        1
  # linear:       1 - layer
  # linearE:      e^(-0.5 - 1) * layer + 1
  # exponential:  e^(-0.5 - layer)
  # quadratic:    e^(-0.5 - 1) * layer^2 + 1
  # sigmoidal:    (1 + e^(-0.5)) / (1 + e^(layer - 0.5))
  layer_penalty: exponential
  flag_imbalance_penalty: false
  flag_importance_penalty: 1
  # sum: Add all the penalties
  # product: Multiply all the penalties
  penalty_aggregation: sum
  num_processes: 10

val:
  from_pid: 1000
  to_pid: 1005
  neg_pos_ratio: ${train.neg_pos_ratio}
  min_samples: ${train.min_samples}
  flag_layer_penalty: ${train.flag_layer_penalty}
  # layer in [0, 1], 0 for root and 1 for terminal
  # const:        1
  # linear:       1 - layer
  # linearE:      e^(-0.5 - 1) * layer + 1
  # exponential:  e^(-0.5 - layer)
  # quadratic:    e^(-0.5 - 1) * layer^2 + 1
  # sigmoidal:    (1 + e^(-0.5)) / (1 + e^(layer - 0.5))
  layer_penalty: ${train.layer_penalty}
  flag_imbalance_penalty: ${train.flag_imbalance_penalty}
  flag_importance_penalty: ${train.flag_importance_penalty}
  # sum: Add all the penalties
  # product: Multiply all the penalties
  penalty_aggregation: ${train.penalty_aggregation}
  batch_size: 512
  shuffle: false
  log_dir: val_log
  every: 5


# Model
mdl:
  # Instance encoder
  ie:
    enc:
      - 8
      - 32
    agg:
      - 32
      - 16
  # Context encoder
  ce:
    enc:
      - 9
      - 32
    agg:
      - 32
      - 16
  # Parent encoder
  pe:
    enc:
      - 3
      - 32
    agg:
      - 32
      - 16
  # Node encoder
  ne:
    - 3
    - 32
    - 16

# Optimizer
opt:
  name: Adam
  lr: 0.001

# Loss function
loss:
  name: BCELoss

seed: 789541

hydra:
  output_subdir: null
  run:
    dir: .
